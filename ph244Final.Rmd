---
title: "ph244 Final Project"
author: "Antonia Gibbs"
date: "5/3/2022"
output: html_document
---


```{r Packages and Data}
library(randomForest)
library(data.table)
library(ggfortify)
library(dplyr)
library(ggplot2)
library(tictoc)
library(datasets)
library(caret)

#reading in data
traindat_all = fread("bioresponse/train.csv", header=T)
testdat = fread("bioresponse/test.csv", header=T)
```


```{r}
# removing outcome
traindat = traindat_all %>% select(-c(Activity))

# identifying columns with 0 variance
which(apply(traindat, 2, var)==0)
which(apply(testdat, 2, var)==0)
# dropping columns with 0 variance in train data
traindat = traindat[ , which(apply(traindat, 2, var) != 0)]
```


```{r}
pca = prcomp(traindat, center=TRUE, scale.=TRUE)
summary(pca)

# # https://cran.r-project.org/web/packages/ggfortify/vignettes/plot_pca.html
# autoplot(pca)


# ggplot2 way - w coloring
dtp <- data.frame('Activity' = traindat_all$Activity, pca$x[,1:2]) # the first two componets are selected (NB: you can also select 3 for 3D plottings or 3+)
ggplot(data = dtp) + 
       geom_point(aes(x = PC1, y = PC2, col = Activity)) + 
       theme_minimal() 
```


```{r}
#calculate total variance explained by each principal component
var_explained = pca$sdev^2 / sum(pca$sdev^2)

# scree plot of all principal components
qplot(c(1:1776), var_explained) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("Variance Explained") +
  ggtitle("Scree Plot") #+
  # ylim(0, 1)

# scree plot of first 5 principal components
qplot(c(1:5), var_explained[1:5]) + 
  geom_line() + 
  xlab("Principal Component") + 
  ylab("Variance Explained") +
  ggtitle("Scree Plot") #+
  # ylim(0, 1)
```

```{r, eval=F, include=F}
sm = 0
counter = 1
while (sm < 0.9){
  sm = sm + var_explained[counter]
  counter = counter + 1
}

counter
var_explained[1:counter] %>% sum()
```


```{r Logistic Regression}
# First, take out variables that have multicollinearity 

#CRASHES
##cor_df <- cor(traindat_all, use = "complete.obs")
#cor_df[upper.tri(cor_df)] <- 0 
#diag(cor_df) <- 0
#train_nocor <- 
#  traindat_all[, !apply(cor_df, 2, function(x) any(abs(x) > 0.75, na.rm = TRUE))]
#dim(train_nocor)

#LR model
tic()
mod.lr <- glm(Activity ~ ., data = traindat_all, family = "binomial")
lr_pred <- predict(mod.lr, newdata = testdat, type = "response")
toc()

head(lr_pred)
```


```{r Random Forest, eval = F}
tic()
mod.rf <- randomForest(Activity~., data=traindat_all, proximity=TRUE, ntree = 100)
toc()
print(rf)
```

```{r Log Loss Metric Function}
#obtain predicted values (which are probabilities) and compare to actual values (which are binary)
LogLoss<-function(actual, predicted)
{
result<- -1/length(actual)*(sum((actual*log(predicted)+(1-actual)*log(1-predicted))))
return(result)
}
```
